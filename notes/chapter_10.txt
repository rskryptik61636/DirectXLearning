chapter 10 - geometry shader

Overview
	- The geometry shader is an optional stage that sits in between the vertex shader and the pixel shader
	
	- It takes in one primitive and outputs zero or more primitives
	
	- The output primitives need not be the same type as that of the input primitives (eg. a point can be turned into a quad, which is what is common apparently)
	
	- The output is synonymous to that of the vertex shader, in that, the output primitives have their points in homogeneous clip space
	
Structure
	- The signature of a typical geometry shader is as follows:
		[maxvertexcount(N)] 
		void ShaderName ( PrimitiveType InputVertexType InputName [NumElements], 
							inout StreamOutputObject<OutputVertexType> OutputName) 
		{ // Geometry shader body... }
		
	- maxvertexcount specifies the maximum no. of vertices that will be output by the geometry shader
		- Lesser no. of vertices can be output but the max no. can never cross maxvertexcount
		
	- Each input primitive has the following:
		- PrimitiveType - type of the incoming primitive (point, line(adj) lists/strips, triangle(adj) lists/strips)
		- InputVertexType - output structure type of the vertex shader
		- NumElements - no. of vertices that compose the incoming primitive
		
	- Each input primitive is completely specified in terms of its vertices. The geometry shader doesn't have to differentiate between lists and strips.
		- Eg., if the input primitives are triangles, each will be specified by three vertices irrespective of whether the primitive type is triangle lists or triangle strips.
		
	- The output is a stream of vertices that can be either points, lines or triangles
		- Vertices are added to the output stream using the intrinsic Append() method
		- The stream typically consists of primitive strips but primitive lists can be generated if required by using the RestartStrip() intrinsic method

	- If an insufficient no. of vertices are provided to describe a primitive, the partial primitive is discarded
	
Billboarding
	- Billboarding is an effect wherein 2D forms of faraway scene objects (such as trees) are rendered instead of their 3D counterparts in order to save on computation
	
	- This technique requires that the billboard is always facing the camera, in the absence of which the hack(?) becomes noticeable
	
	- Given the eye position (Ex, Ey, Ez) and the center of the billboard (Cx, Cy, Cz) in world space; it is possible to construct an orthonormal bases (left-handed)
	  which describes the world space transformation of the billboard
		- w = norm([Ex, 0, Ez] - [Cx, 0, Cz]); note that the y component is discarded as the billboard is projected on the xz plane so that it is always facing the camera
												and to account for the assumption that the up vector is aligned with the y axis
		- v = (0, 1, 0)
		- u = cross(v, w)
		- World = |ux, uy, uz, 0|
				  |vx, vy, vz, 0|
				  |wx, wy, wz, 0|
				  |Cx, Cy, Cz, 1|
				  
	- The billboard positions will be points initially and the geometry shader will expand those points into quads on which the billboard texture will be applied
	
SV_PrimitiveID
	- The geometry shader can take in a primitive ID which will result in an ID in the range [0,n) being assigned to each primitive generated by the geometry shader
	
	- The geometry shader can either use the primitive ID or pass it on to the pixel shader (which is what happens in the case of billboarding, so that the pixel shader
	  can use it as a reference into the texture array)
	  
	- If a geometry shader is present in the pipeline then the primitive ID must be bound to it. Whether it is used by the geometry shader or passed on to the pixel shader
	  is upto the geometry shader.
	  
	- Optionally, it is possible for the input assembler stage to generate a vertex ID that is passed into the vertex shader that will result in a similar effect wherein
	  all the vertices 
	  
Texture arrays
	- When texture arrays are used in a pixel shader, 3D texture coordinates are specified wherein:
		- The first two components are the usual 'u' and 'v' texture components
		- The third component 'w' is the index into the texture array
		
	- A literal index into the texture array will not work (unless it is hardcoded),
	  because the possibility exists that it can vary per pixel and HLSL doesn't like that
	  
	- A texture array can be created by loading textures from multiple files and creating Texture2D and ShaderResourceView objects from them
		- Loading textures from multiple files is the simplest approach for now, should look into loading multiple images from a single file when the time comes
		- A helper function exists in the tutorial projects to create a texture array from specified files, can do something similar with DXTK's Create(DDS/WIC)TextureFromFile funcs
		- Create(DDS/WIC)TextureFromFileEx exposes additional params which can be used to configure the texture loading
		- Might be able to use Create(DDS/WIC)TextureFromFile functions themselves, default values of the extra params will do for now
		- So far, the shader resource view that is returned by the functions have been used and the resource objects have been ignored
		- For this, the resource objects can be used and the shader resource view object can be created manually
		- The same function can be used with the only change being that the loading of the textures will be handled by the above mentioned functions
		
Texture subresources
	- A texture array consists of a set of textures with their individual mipmap chains (all chains having the same depth)
	
	- A texture with all its mipmap levels is referred to as an array slice
	
	- The set of all textures at a given mipmap level is referred to as a mip slice
	
	- A single mipmap level of a given texture is referred to as a subresource
	
	- The subresources are stored in column-major order starting from the first texture and the highest mipmap level
		- Each row is a mip slice and each column is an array slice
	
TODO: talk about loading textures and texture subresources

- test the lit sphere normal calculation using the phong/toon shader

- need to create shader variables for the phong/toon shader
	- light
	- lighting type: 0 Phong should be enough
	- shader impl type: 0 vertex shader
	- eye pos world space
	- world matrix
	- wvp matrix

- lighting seems off for one of the sets of triangles (investigate later)

- add geometry shader
	- vertex shader just passes vIn to vOut
	- geometry shader does what it needs to
		- copy diffuse and specular colors over
		- transform surface normal to world space
		- compute edge mid-points and generate sub-triangles vertices list
	- pixel shader outputs the computed color
	
- try computing normals as just normals of the sphere	

- made some progress on this ancient issue, it looks more like a sphere now after specifying each sub-triangle separately but there are many holes in the sphere

- try breaking the geometry shader into subfunctions like it is specified in the book and see what happens
	- first make sure that the vertices and indices are specified correctly in the first place
	
- it seems to work now, an issue was that the vertices were being scaled internally by the ObjectV2 base class, which is not nice

- the original implementation works of finding the midpoints of the 3 edges of the triangle and subdividing from there

- normals effect
	- the objective is to render the normals of the icosahedron points using the geometry shader
	
	- this is a separate effect from the subdivision effect and is applied after the subdivision effect
	
	- need to override the buildFX method to compile the normals effect as well